{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำตอบ: สวัสดีครับ!\n",
      "\n",
      "Data Science (วิทยาศาสตร์ข้อมูล) คือศาสตร์ที่ผสมผสานความรู้จากหลายสาขา เช่น **สถิติ, คณิตศาสตร์, คอมพิวเตอร์ และความรู้เฉพาะทางในธุรกิจ** เพื่อ **ดึงข้อมูลเชิงลึกที่มีคุณค่าจากข้อมูลจำนวนมหาศาล**\n",
      "\n",
      "**พูดง่ายๆ ก็คือ:**\n",
      "\n",
      "*   **เก็บข้อมูล:** รวบรวมข้อมูลจากแหล่งต่างๆ\n",
      "*   **วิเคราะห์ข้อมูล:** ใช้เทคนิคทางสถิติและ Machine Learning เพื่อหาความสัมพันธ์, รูปแบบ และแนวโน้ม\n",
      "*   **นำเสนอข้อมูล:** สื่อสารผลลัพธ์ที่ได้ออกมาในรูปแบบที่เข้าใจง่าย (เช่น กราฟ, ตาราง, หรือรายงาน)\n",
      "*   **ใช้ข้อมูลเพื่อตัดสินใจ:** ช่วยให้องค์กรตัดสินใจได้อย่างมีข้อมูลรองรับ\n",
      "\n",
      "**ตัวอย่างการใช้งาน:**\n",
      "\n",
      "*   Netflix แนะนำหนังให้คุณดูตามประวัติการรับชม\n",
      "*   ธนาคารตรวจจับการทุจริตในการทำธุรกรรม\n",
      "*   แพทย์วินิจฉัยโรคด้วยการวิเคราะห์ข้อมูลผู้ป่วย\n",
      "\n",
      "หวังว่าคำอธิบายนี้จะช่วยให้เข้าใจ Data Science มากขึ้นนะครับ!\n",
      "เวลา: 37.18027591705322 นาที\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "response = ollama.chat(\n",
    "    model='gemma3:12b',\n",
    "    messages=[{'role': 'user', 'content': 'สวัสดี! อธิบายสั้นๆ ว่า Data Science คืออะไร?'}]\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"คำตอบ:\", response['message']['content'])\n",
    "print(\"เวลา:\", end_time - start_time, \"นาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำตอบ: ```python\n",
      "import pandas as pd\n",
      "\n",
      "def calculate_average_sales(csv_file_path):\n",
      "  \"\"\"\n",
      "  อ่านไฟล์ CSV, คำนวณค่าเฉลี่ยของคอลัมน์ 'sales', และจัดการ missing values\n",
      "\n",
      "  Args:\n",
      "    csv_file_path (str): พาธไปยังไฟล์ CSV\n",
      "\n",
      "  Returns:\n",
      "    float: ค่าเฉลี่ยของคอลัมน์ 'sales' หลังจากจัดการ missing values แล้ว\n",
      "    หรือ None หากเกิดข้อผิดพลาดในการอ่านไฟล์\n",
      "  \"\"\"\n",
      "  try:\n",
      "    # อ่านไฟล์ CSV ด้วย pandas\n",
      "    df = pd.read_csv(csv_file_path)\n",
      "\n",
      "    # ตรวจสอบว่าคอลัมน์ 'sales' มีอยู่ใน DataFrame หรือไม่\n",
      "    if 'sales' not in df.columns:\n",
      "      print(\"Error: Column 'sales' not found in the CSV file.\")\n",
      "      return None\n",
      "\n",
      "    # คำนวณค่าเฉลี่ยของคอลัมน์ 'sales' ก่อนจัดการ missing values\n",
      "    mean_sales = df['sales'].mean()\n",
      "\n",
      "    # เติม missing values ในคอลัมน์ 'sales' ด้วยค่าเฉลี่ย\n",
      "    df['sales'].fillna(mean_sales, inplace=True)\n",
      "\n",
      "    # คำนวณค่าเฉลี่ยของคอลัมน์ 'sales' อีกครั้งหลังจากเติม missing values\n",
      "    mean_sales_filled = df['sales'].mean()\n",
      "\n",
      "    return mean_sales_filled\n",
      "\n",
      "  except FileNotFoundError:\n",
      "    print(f\"Error: File not found at {csv_file_path}\")\n",
      "    return None\n",
      "  except pd.errors.EmptyDataError:\n",
      "    print(f\"Error: The file {csv_file_path} is empty.\")\n",
      "    return None\n",
      "  except Exception as e:\n",
      "    print(f\"An unexpected error occurred: {e}\")\n",
      "    return None\n",
      "\n",
      "\n",
      "# ตัวอย่างการใช้งาน\n",
      "file_path = 'sales_data.csv'  # แทนที่ด้วยพาธไฟล์ CSV ของคุณ\n",
      "\n",
      "# สร้างไฟล์ CSV ตัวอย่างสำหรับทดสอบ (ถ้ายังไม่มี)\n",
      "data = {'sales': [100, 150, None, 200, 250, None]}\n",
      "df_example = pd.DataFrame(data)\n",
      "df_example.to_csv(file_path, index=False)\n",
      "\n",
      "average_sales = calculate_average_sales(file_path)\n",
      "\n",
      "if average_sales is not None:\n",
      "  print(f\"ค่าเฉลี่ยของคอลัมน์ 'sales' (หลังจากเติม missing values): {average_sales}\")\n",
      "```\n",
      "\n",
      "**คำอธิบายโค้ด:**\n",
      "\n",
      "1. **`calculate_average_sales(csv_file_path)`:** ฟังก์ชันหลักที่รับพาธไฟล์ CSV เป็นอาร์กิวเมนต์\n",
      "2. **`try...except` block:** ใช้เพื่อจัดการข้อผิดพลาดที่อาจเกิดขึ้น เช่น ไฟล์ไม่พบ, ไฟล์ว่าง, หรือข้อผิดพลาดอื่นๆ ระหว่างการประมวลผล\n",
      "3. **`pd.read_csv(csv_file_path)`:** อ่านไฟล์ CSV เข้า DataFrame ของ pandas\n",
      "4. **`if 'sales' not in df.columns:`:** ตรวจสอบว่ามีคอลัมน์ชื่อ 'sales' ใน DataFrame หรือไม่ ถ้าไม่มี จะพิมพ์ข้อผิดพลาดและคืนค่า `None`\n",
      "5. **`df['sales'].mean()`:**  คำนวณค่าเฉลี่ยของคอลัมน์ 'sales' **ก่อน** เติม missing values  (เพื่อให้ทราบค่าเฉลี่ยเดิม)\n",
      "6. **`df['sales'].fillna(mean_sales, inplace=True)`:**  เติม missing values (NaN) ในคอลัมน์ 'sales' ด้วยค่าเฉลี่ยที่คำนวณไว้ในขั้นตอนก่อนหน้า `mean_sales`  `inplace=True` หมายถึงการแก้ไข DataFrame โดยตรงโดยไม่ต้องสร้างสำเนา\n",
      "7. **`df['sales'].mean()`:** คำนวณค่าเฉลี่ยของคอลัมน์ 'sales' อีกครั้ง **หลัง** จากเติม missing values  (เพื่อให้ทราบค่าเฉลี่ยใหม่หลังจากเติมข้อมูล)\n",
      "8. **`return mean_sales_filled`:** คืนค่าเฉลี่ยใหม่\n",
      "9. **`except FileNotFoundError`:** จับข้อผิดพลาดหากไฟล์ไม่พบ\n",
      "10. **`except pd.errors.EmptyDataError`:** จับข้อผิดพลาดหากไฟล์ว่าง\n",
      "11. **`except Exception as e`:**  จัดการข้อผิดพลาดอื่นๆ ที่อาจเกิดขึ้น  พิมพ์ข้อผิดพลาดและคืนค่า `None`\n",
      "12. **ตัวอย่างการใช้งาน:**\n",
      "   - กำหนดค่า `file_path` ให้ตรงกับพาธไฟล์ CSV ของคุณ\n",
      "   - สร้าง DataFrame ตัวอย่างเพื่อสร้างไฟล์ CSV สำหรับทดสอบ (ถ้ายังไม่มี)\n",
      "   - เรียกใช้ฟังก์ชัน `calculate_average_sales()` และพิมพ์ผลลัพธ์\n",
      "\n",
      "**วิธีใช้งาน:**\n",
      "\n",
      "1. **ติดตั้ง pandas:**  หากยังไม่ได้ติดตั้ง pandas ให้ติดตั้งด้วยคำสั่ง `pip install pandas`\n",
      "2. **บันทึกโค้ด:** บันทึกโค้ดเป็นไฟล์ Python (เช่น `calculate_sales.py`).\n",
      "3. **แก้ไข `file_path`:** แก้ไขตัวแปร `file_path` ในโค้ดให้ชี้ไปยังไฟล์ CSV ของคุณ\n",
      "4. **รันโค้ด:** รันไฟล์ Python จาก command line: `python calculate_sales.py`\n",
      "\n",
      "**ข้อควรระวัง:**\n",
      "\n",
      "* **`file_path`:** ตรวจสอบให้แน่ใจว่าพาธไฟล์ CSV ถูกต้อง\n",
      "* **คอลัมน์ 'sales':** ตรวจสอบให้แน่ใจว่าไฟล์ CSV มีคอลัมน์ชื่อ 'sales'\n",
      "* **ข้อมูลในคอลัมน์ 'sales':** ข้อมูลในคอลัมน์ 'sales' ควรเป็นตัวเลข (integer หรือ float)\n",
      "* **Missing values:** โค้ดนี้จะเติม missing values ด้วยค่าเฉลี่ยของคอลัมน์ 'sales'  หากต้องการใช้วิธีอื่นในการจัดการ missing values (เช่น เติมด้วยค่า 0, เติมด้วยค่ากลาง, หรือลบแถวที่มี missing values) ให้ปรับแก้โค้ดในส่วนของ `df['sales'].fillna()`  ตามความเหมาะสม\n",
      "\n",
      "เวลา: 192.06383109092712 วินาที\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "response = ollama.chat(\n",
    "    model='gemma3:12b',\n",
    "    messages=[{'role': 'user', 'content': \"เขียนโค้ด Python ใช้ pandas อ่านไฟล์ CSV และหาค่าเฉลี่ยของคอลัมน์ 'sales' พร้อมทั้งจัดการ missing values ด้วยการเติมค่าเฉลี่ย\"}]\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"คำตอบ:\", response['message']['content'])\n",
    "print(\"เวลา:\", end_time - start_time, \"วินาที\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "คำตอบ: ```python\n",
      "import numpy as np\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
      "from sklearn.datasets import make_classification  # ใช้เพื่อสร้าง dataset จำลอง\n",
      "\n",
      "# 1. สร้าง dataset จำลอง (ใช้เพื่อให้โค้ดทำงานได้ แม้จะไม่มี dataset จริง)\n",
      "# คุณสามารถเปลี่ยนส่วนนี้เพื่อโหลด dataset ของคุณเอง\n",
      "X, y = make_classification(n_samples=1000, n_features=20, random_state=42,\n",
      "                           n_informative=15, n_redundant=5, n_repeated=0,\n",
      "                           n_classes=2, class_sep=1.0, flip_y=0.1)\n",
      "\n",
      "# 2. แบ่ง dataset เป็น training set และ testing set\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "\n",
      "# 3. สร้างโมเดล Random Forest Classifier\n",
      "model = RandomForestClassifier(n_estimators=100, random_state=42)  # ปรับ hyperparameters ได้ตามต้องการ\n",
      "\n",
      "# 4. ทำ Cross-validation 5-fold\n",
      "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
      "print(\"Cross-validation scores:\", scores)\n",
      "print(\"Mean cross-validation accuracy:\", scores.mean())\n",
      "\n",
      "# 5. ฝึกโมเดลบน training set\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# 6. ทำนายผลลัพธ์บน testing set\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "# 7. คำนวณ accuracy\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "print(\"Accuracy:\", accuracy)\n",
      "\n",
      "# 8. คำนวณ confusion matrix\n",
      "cm = confusion_matrix(y_test, y_pred)\n",
      "print(\"Confusion Matrix:\\n\", cm)\n",
      "\n",
      "# 9. สร้าง classification report\n",
      "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
      "\n",
      "```\n",
      "\n",
      "**คำอธิบายโค้ด:**\n",
      "\n",
      "1. **Import Libraries:** นำเข้าไลบรารีที่จำเป็น:\n",
      "   - `numpy`: สำหรับการคำนวณทางคณิตศาสตร์\n",
      "   - `sklearn.model_selection`: สำหรับการแบ่ง dataset และ cross-validation\n",
      "   - `sklearn.ensemble`: สำหรับ Random Forest Classifier\n",
      "   - `sklearn.metrics`: สำหรับการวัดผลประสิทธิภาพของโมเดล\n",
      "\n",
      "2. **สร้าง Dataset จำลอง:**  `make_classification` สร้าง dataset จำลองเพื่อทดสอบโค้ด หากคุณมี dataset ของคุณเอง ให้แทนที่ส่วนนี้ด้วยการโหลด dataset ของคุณ\n",
      "\n",
      "3. **แบ่ง Dataset:**  `train_test_split` แบ่ง dataset เป็น training set (สำหรับฝึกโมเดล) และ testing set (สำหรับประเมินประสิทธิภาพของโมเดล) `test_size=0.2` หมายถึง 20% ของข้อมูลทั้งหมดจะถูกใช้สำหรับ testing set  `random_state` กำหนด seed สำหรับการสุ่ม เพื่อให้ได้ผลลัพธ์ที่สอดคล้องกันทุกครั้งที่รันโค้ด\n",
      "\n",
      "4. **สร้างโมเดล:**  `RandomForestClassifier` สร้างโมเดล Random Forest  `n_estimators=100` หมายถึง จำนวนต้นไม้ใน Random Forest (ปรับแต่งค่านี้ได้)  `random_state` กำหนด seed สำหรับการสุ่ม เพื่อให้ได้ผลลัพธ์ที่สอดคล้องกันทุกครั้งที่รันโค้ด\n",
      "\n",
      "5. **Cross-Validation:** `cross_val_score` ทำ cross-validation 5-fold เพื่อประเมินประสิทธิภาพของโมเดลอย่างแม่นยำยิ่งขึ้น  `cv=5` หมายถึง ข้อมูลจะถูกแบ่งออกเป็น 5 ส่วน และโมเดลจะถูกฝึกฝนบน 4 ส่วน และทดสอบบนส่วนที่เหลือ  `scoring='accuracy'` กำหนดว่าจะใช้ accuracy เป็น metric ในการประเมิน\n",
      "\n",
      "6. **ฝึกโมเดล:**  `model.fit(X_train, y_train)` ฝึกโมเดลบน training set\n",
      "\n",
      "7. **ทำนายผลลัพธ์:**  `model.predict(X_test)` ทำนายผลลัพธ์บน testing set\n",
      "\n",
      "8. **คำนวณ Accuracy:**  `accuracy_score` คำนวณ accuracy ของโมเดลบน testing set\n",
      "\n",
      "9. **คำนวณ Confusion Matrix:** `confusion_matrix` สร้าง confusion matrix เพื่อแสดงผลการทำนายของโมเดลอย่างละเอียด\n",
      "\n",
      "10. **สร้าง Classification Report:** `classification_report` สร้างรายงานที่สรุปผลการประเมินโมเดล รวมถึง precision, recall, f1-score และ support\n",
      "\n",
      "**วิธีการใช้งาน:**\n",
      "\n",
      "1. **ติดตั้งไลบรารี:**  หากยังไม่ได้ติดตั้ง ให้ติดตั้งไลบรารีที่จำเป็นโดยใช้ pip:\n",
      "   ```bash\n",
      "   pip install numpy scikit-learn\n",
      "   ```\n",
      "\n",
      "2. **ปรับแต่งโค้ด:**\n",
      "   - **โหลด Dataset:** แทนที่ส่วน `make_classification` ด้วยโค้ดที่โหลด dataset ของคุณเอง\n",
      "   - **ปรับ Hyperparameters:** ปรับค่า hyperparameters ของ `RandomForestClassifier` เช่น `n_estimators`, `max_depth`, `min_samples_leaf` เพื่อให้ได้ประสิทธิภาพที่ดีที่สุดสำหรับ dataset ของคุณ\n",
      "   - **ปรับ Metric:** ถ้าต้องการใช้ metric อื่นในการประเมิน (เช่น precision, recall, f1-score) ให้ปรับ `scoring` ใน `cross_val_score` และ `classification_report`\n",
      "\n",
      "3. **รันโค้ด:**  รันโค้ด Python ใน environment ที่ติดตั้งไลบรารีแล้ว\n",
      "\n",
      "**ข้อควรจำ:**\n",
      "\n",
      "* `random_state`: การกำหนดค่า `random_state` จะช่วยให้ได้ผลลัพธ์ที่สอดคล้องกันทุกครั้งที่รันโค้ด\n",
      "* **Hyperparameter Tuning:** การปรับแต่ง hyperparameters เป็นสิ่งสำคัญเพื่อให้ได้ประสิทธิภาพที่ดีที่สุดสำหรับ dataset ของคุณ\n",
      "* **Dataset Size:**  ประสิทธิภาพของโมเดลขึ้นอยู่กับขนาดและคุณภาพของ dataset\n",
      "* **Feature Engineering:** การสร้าง features ที่มีคุณภาพสูงสามารถปรับปรุงประสิทธิภาพของโมเดลได้อย่างมาก\n",
      "\n",
      "เวลา: 197.55548906326294 วินาที\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "response = ollama.chat(\n",
    "    model='gemma3:12b',\n",
    "    messages=[{'role': 'user', 'content': \"เขียนโค้ด Python ใช้ scikit-learn สร้างโมเดล Random Forest สำหรับ classification, ทำ cross-validation 5-fold, และคำนวณ accuracy กับ confusion matrix\"}]\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"คำตอบ:\", response['message']['content'])\n",
    "print(\"เวลา:\", end_time - start_time, \"วินาที\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
